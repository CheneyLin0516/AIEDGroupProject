import os
from crewai import Agent, Task, Crew, Process
from langchain_groq.chat_models import ChatGroq
import chainlit as cl
from crewai_tools import PDFSearchTool
from chainlit import make_async
from crewai_tools import tool
from chainlit import run_sync
from crewai import LLM

# llm = LLM(
#     model="gemini/gemini-pro",
#     api_key="your_api_key",
#     # Include other necessary parameters
# )
# llm = ChatGoogleGenerativeAI(
#     model="google/gemini-1.5-pro",
#     temperature=0,
#     max_tokens=None,
#     timeout=None,
#     max_retries=2,
#     # other params...
# )

llm = ChatGroq(model_name="groq/llama3-70b-8192")

summary=""
evaluation=""
explanation=""

@tool("Ask Human the question")
def ask_human(question: str) -> str:
    """Ask the question to the human user"""
    human_response  = run_sync( cl.AskUserMessage(content=f"{question}",author="Teacher").send())
    cl.Message(content=human_response).send()
    if human_response:
        return human_response["output"]

def setup_rag_tool(pdf_path):
    """Initialize RAG tool with the provided PDF"""
    return PDFSearchTool(
        pdf=pdf_path,
        config=dict(
            llm=dict(
                provider="groq",
                config=dict(
                    base_url="https://api.groq.com/openai/v1",
                    api_key=os.environ['GROQ_API_KEY'],
                    model="groq/mixtral-8x7b-32768"
                ),
            ),
            embedder=dict(
                provider="huggingface",
                config=dict(
                    model="BAAI/bge-small-en-v1.5",
                ),
            ),
        )
    )
@cl.on_chat_start
async def on_chat_start():
    """Initialize the chat session"""
    await cl.Message(
        content="# Welcome to PrepMaster! :rocket::robot_face:\nHere, you will be helped by a team of virtual experts to better prepare for the weekly course."
    ).send()
    
    # Ask for PDF upload
    files = await cl.AskFileMessage(
        content="Please upload your weekly learning materials",
        accept=["application/pdf"],
        max_size_mb=20,
    ).send()
    
    # Initialize learning session
    print("Files:", files)
    rag_tool = setup_rag_tool(files[0].path)
    
    # Agents
    learning_content_analyst= Agent(
                role='LearningContentAnalyst',
                goal='Extract key insights from the uploaded PDF and generate a summary.',
                backstory="An expert in academic material analysis who simplifies complex content into actionable summaries.",
                tools=[rag_tool],
                llm=llm
            )
    question_generator = Agent(
                role='QuestionGenerator',
                goal='Create one targeted question to assess understanding of the material at different stages of learning.',
                backstory="A question-crafting specialist who focuses on promoting deep comprehension through the engaging and relevant question.",
                tools=[],
                llm=llm
            )
    questioner = Agent(
                role='Questioner',
                goal="Ask the question generated by the Question Generator and accurately record the human’s responses.",
                backstory="A curious and empathetic specialist who facilitates question asking. Allows human to think for answers",
                tools=[ask_human],
                llm=llm
    )
    evaluator = Agent(
                role='Evaluator',
                goal='Evaluate pre-test and post-test answers, giving constructive feedback and suggestions.',
                backstory="An evaluation specialist who supports learning sessions by providing actionable insights.",
                tools=[],
                llm=llm
            )
    facilitator = Agent(
                role='Facilitator',
                goal="""Conduct a learning session focusing on one weakness of the human in the {evaluation}.
    The session includes the following:
    1. Ask **ONE** thoughtful question related to the weakness identified in the {evaluation}.
    2. Wait for the user's response. Assess whether the response is correct or sufficient. Do not ask more than one question at this stage.
    3. If the user's response is incorrect or incomplete, provide a clear explanation using relevant concepts from the {summary} and {evaluation}.
    4. Conclude by briefly summarizing the key concepts covered during the session.""",
                backstory="A supportive guide who fosters meaningful learning experiences through personalized interactions.",
                # goal='Guide the human to learn and deeply understand the weekly content by addressing their knowledge gaps showed in the {evaluation}. Use a targeted question and clear, concise explanation to ensure effective learning.',
                # backstory="You are a supportive and approachable facilitator, skilled at creating engaging learning experiences. Your primary objective is to help the human grasp key concepts from the weekly content by identifying their weaknesses, reinforcing their strengths, and fostering critical thinking",
                tools=[ask_human],
                llm=llm
        )

    # Tasks
    learning_content_analysis = Task( #crew 1
                description="Analyze the uploaded PDF and focus on weekly objectives, essential keywords, and main ideas.",
                expected_output="A concise summary (100-150 words) that highlights: 3 weekly objectives, 3 essential keywords, and main ideas.",
                agent=learning_content_analyst
            )
    question_generation =Task( #crew 2
                description="Generate one open-ended question based on the {summary}.",
                expected_output="A question that aligns with the {summary} for the questioner.",
                agent=question_generator
            )
    question_asking = Task( #crew 2
                description="Pose the pretest question from the question generator to the user and record their response verbatim.",
                expected_output="The exact text of the user’s response.",
                context=[question_generation],
                agent=questioner
            )
    evaluation = Task( #crew 2
                description="Assess responses fairly and provide: feedback on correct/incorrect aspects, and suggested resources for improvement",
                expected_output="Comprehensive feedback for improvement.",
                context=[question_generation, question_asking],
                agent=evaluator
            )
    facilitation = Task( #crew 3
                description="""Conduct a learning session for one weakness mentioned in the {evaluation}.
    The session includes the following:
    1. Ask **ONE** thoughtful question related to the weakness identified in the {evaluation}.
    2. Wait for the user's response. Assess whether the response is correct or sufficient. Do not ask more than one question at this stage.
    3. If the user's response is incorrect or incomplete, provide a clear explanation.
    4. Conclude by briefly summarizing the key concept related to the weakness covered during the session.""",
                expected_output="""A concise summary of the question and explanation.""",
                agent=facilitator,
                tools=[ask_human]
            )
    post_question_generation = Task( #crew 4
                description="Generate one open-ended posttest question based on the {explanation}.",
                expected_output="A question that effectively evaluates understanding of the concepts discussed during the learning session.",
                context=[facilitation],
                agent=question_generator
            )
    post_question_asking =Task( #crew 4
                description="Pose the posttest question from question generator to the user and record their response verbatim.",
                expected_output="The exact text of the user’s response.",
                context=[question_generation],
                agent=questioner
            )
    post_evaluation=Task( #crew 4
                description="Evaluate the answer given in a fair way.",
                expected_output="The feedback on what was right or wrong and a list of resources to learn more about it",
                context=[question_generation, question_asking],
                agent=evaluator
            )

    # Crews
    analysis_crew = Crew(
                agents=[learning_content_analyst],
                tasks=[learning_content_analysis],
                verbose=True,
                process= Process.sequential
            )
    pretest_crew = Crew(
                agents=[question_generator, questioner, evaluator],
                tasks=[question_generation, question_asking, evaluation],
                verbose=True,
                process=Process.sequential
            )
    facilitation_crew = Crew(
                agents=[facilitator],
                tasks=[facilitation],
                verbose=True,
                process=Process.sequential
    )
    posttest_crew= Crew(
                agents=[question_generator, questioner, evaluator],
                tasks=[post_question_generation, post_question_asking, post_evaluation],
                verbose=True,
                process=Process.sequential
            )

    # User sessions 
    cl.user_session.set('analysis_crew', analysis_crew)
    cl.user_session.set('pretest_crew', pretest_crew)
    cl.user_session.set('facilitation_crew', facilitation_crew)
    cl.user_session.set('posttest_crew', posttest_crew)
    cl.user_session.set('phase', "analysis")
    await cl.Message(content=f"PDF successfully analysed! Tell me to start", author="Crew").send()

@cl.on_message
async def main(message: cl.Message):
    global summary
    global evaluation
    global explanation

    if(cl.user_session.get("phase")=="analysis"):
        crew = cl.user_session.get('analysis_crew')
        crew_call = make_async(crew.kickoff)
        crew_output = await crew_call()
        print (crew_output)
        for output in crew_output.tasks_output:
            msg = cl.Message(content=output.raw,author=output.agent)
            await msg.send()
            await msg.update()
        summary=crew_output.raw
        cl.user_session.set("phase", "pretest")
        await cl.Message(content="Ready to check your current knowledge? Type 'start' to begin the Pretest Session.").send()

    elif(cl.user_session.get("phase")=="pretest"):
        crew = cl.user_session.get('pretest_crew')
        inputs = {
            "summary": summary
        }
        crew_call = make_async(crew.kickoff)
        crew_output = await crew_call(inputs=inputs) 
        # crew_output = crew.kickoff(inputs=inputs)
        for output in crew_output.tasks_output:
            msg = cl.Message(content=output.raw,author=output.agent)
            await msg.send()
            await msg.update()
        evaluation=crew_output.raw 
        cl.user_session.set("phase", "facilitation")
        await cl.Message(content="Thank you for your answers. Do you want to start the Learning Session?").send()

    elif(cl.user_session.get("phase")=="facilitation"):
        crew = cl.user_session.get('facilitation_crew')
        inputs = {
            "evaluation": evaluation,
            "summary": summary
        }
        crew_call = make_async(crew.kickoff)
        crew_output = await crew_call(inputs=inputs)
        for output in crew_output.tasks_output:
            msg = cl.Message(content=output.raw,author=output.agent)
            await msg.send()
            await msg.update()
        explanation=crew_output.raw 
        cl.user_session.set("phase", "posttest")
        await cl.Message(content="Are you ready for a question to review what you have learned?").send()

    elif(cl.user_session.get("phase")=="posttest"):
        crew = cl.user_session.get('posttest_crew')
        # question = message.content
        inputs = {
            "explanation": explanation
        }
        crew_call = make_async(crew.kickoff)
        crew_output = await crew_call()
        crew_output = crew.kickoff(inputs=inputs)
        for output in crew_output.tasks_output:
            msg = cl.Message(content=output.raw,author=output.agent)
            await msg.send()
            await msg.update()
        # cl.user_session.set("phase", "summary")
        await cl.Message(content="You've done well in this weekly preparation. Feel free to add the Summary to your weekly note. Enjoy the coming class!").send()
        
    # elif(cl.user_session.get("phase")=="summary"):
    #     crew = cl.user_session.get('summary_crew')
    #     question = message.content
    #     crew_call = make_async(crew.kickoff)
    #     crew_output = await crew_call()
    #     for output in crew_output.tasks_output:
    #         msg = cl.Message(content=output.raw,author=output.agent)
    #         await msg.send()
    #         await msg.update()
    #     await cl.Message(content="The learning session is complete. Feel free to add the Summary to your weekly note. Enjoy the coming class!").send()
